{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color:#C0392B; text-align: center;color:#19180F; font-size:40px; font-family:Arial; padding:10px; border: 5px solid #19180F; border-radius:10px\">\n",
    "Build a Text Multi-Class Classification Model using BERT\n",
    " </div>\n",
    "\n",
    "<div style=\"background-color:#D98880; color:#19180F; text-align: center;font-size:30px; font-family:Arial; padding:10px; border: 5px solid #19180F; border-radius:10px\"> Introduction & Motivation </div>\n",
    "<div style=\"background-color:#D5D9F2; color:#19180F; font-size:20px; font-family:verdana; padding:10px; border: 5px solid #19180F; border-radius:10px \"> \n",
    "In this notebook we are going to present our DCGAN. Its purpose is to generate\n",
    "fake images that look like real images, after training on a particular dataset. \n",
    "We were interested in GANs because we  thought it would be really interesting to \n",
    "dive into the details of training one. For other types of deep learning \n",
    "architectures, it can be pretty straightforward to train a network, but that is \n",
    "not the case with GANs.\n",
    "</div>\n",
    "\n",
    "\n",
    "\n",
    "<div style=\"background-color:#D5D9F2; color:#19180F; font-size:20px; font-family:verdana; padding:10px; border: 5px solid #19180F; border-radius:10px \"> \n",
    "Our training was executed on NVIDIA's last generation GPUs, `A100`. because on CPU this took more then 5 hours, And this is for `128x128` images.\n",
    "We will discuss about scaling up our GAN later.  \n",
    "</div>\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color:#F0E3D2; color:#19180F; font-size:15px; font-family:Verdana; padding:10px; border: 2px solid #19180F; border-radius:10px\"> \n",
    "ðŸ“Œ\n",
    "Importing modules\n",
    "    </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/elhabachi/miniconda3/envs/chatbot/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import torch\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import torch.nn as nn\n",
    "from transformers import BertModel\n",
    "from transformers import BertTokenizer\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 1e-3\n",
    "seq_len = 20\n",
    "dropout = 0.5\n",
    "num_epochs = 10\n",
    "\n",
    "label_col = \"Product\"\n",
    "tokens_path = \"Output/tokens.pkl\"\n",
    "labels_path = \"Output/labels.pkl\"\n",
    "data_path = \"Input/complaints.csv\"\n",
    "model_path = \"Output/bert_pre_trained.pth\"\n",
    "text_col_name = \"Consumer complaint narrative\"\n",
    "label_encoder_path = \"Output/label_encoder.pkl\"\n",
    "product_map = {'Vehicle loan or lease': 'vehicle_loan',\n",
    "               'Credit reporting, credit repair services, or other personal consumer reports': 'credit_report',\n",
    "               'Credit card or prepaid card': 'card',\n",
    "               'Money transfer, virtual currency, or money service': 'money_transfer',\n",
    "               'virtual currency': 'money_transfer',\n",
    "               'Mortgage': 'mortgage',\n",
    "               'Payday loan, title loan, or personal loan': 'loan',\n",
    "               'Debt collection': 'debt_collection',\n",
    "               'Checking or savings account': 'savings_account',\n",
    "               'Credit card': 'card',\n",
    "               'Bank account or service': 'savings_account',\n",
    "               'Credit reporting': 'credit_report',\n",
    "               'Prepaid card': 'card',\n",
    "               'Payday loan': 'loan',\n",
    "               'Other financial service': 'others',\n",
    "               'Virtual currency': 'money_transfer',\n",
    "               'Student loan': 'loan',\n",
    "               'Consumer Loan': 'loan',\n",
    "               'Money transfers': 'money_transfer'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_file(name, obj):\n",
    "    \"\"\"\n",
    "    Function to save an object as pickle file\n",
    "    \"\"\"\n",
    "    with open(name, 'wb') as f:\n",
    "        pickle.dump(obj, f)\n",
    "\n",
    "\n",
    "def load_file(name):\n",
    "    \"\"\"\n",
    "    Function to load a pickle object\n",
    "    \"\"\"\n",
    "    return pickle.load(open(name, \"rb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color:#F1C40F; color:#C0392B; font-size:40px; font-family:Arial; padding:10px; border: 5px solid #19180F; border-radius:10px\"> I. Text Data Processing</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pd.read_csv(data_path, delimiter=',', quotechar='\"',  engine='python',on_bad_lines='skip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.dropna(subset=[text_col_name], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.replace({label_col: product_map}, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color:#F0E3D2; color:#19180F; font-size:15px; font-family:Verdana; padding:10px; border: 2px solid #19180F; border-radius:10px\"> \n",
    "ðŸ“Œ\n",
    "Encode labels\n",
    "    </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_encoder = LabelEncoder()\n",
    "label_encoder.fit(data[label_col])\n",
    "labels = label_encoder.transform(data[label_col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_file(labels_path, labels)\n",
    "save_file(label_encoder_path, label_encoder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<div style=\"background-color:#F0E3D2; color:#19180F; font-size:15px; font-family:Verdana; padding:10px; border: 2px solid #19180F; border-radius:10px\"> \n",
    "ðŸ“Œ\n",
    "Process the text column\n",
    "    </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_text = list(data[text_col_name])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "241440"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(input_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 241440/241440 [00:00<00:00, 789488.35it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 241440/241440 [00:00<00:00, 561876.15it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 241440/241440 [00:03<00:00, 69203.93it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 241440/241440 [00:03<00:00, 78467.44it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 241440/241440 [00:09<00:00, 25282.87it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 241440/241440 [00:00<00:00, 551770.24it/s]\n"
     ]
    }
   ],
   "source": [
    "## convert text to lower case \n",
    "input_text=[i.lower() for i in tqdm(input_text)]\n",
    "\n",
    "## remove punctuations except apostrophe\n",
    "input_text= [re.sub(r'\\{\\$\\d+\\.\\d{2}\\}',\"\",i) for i in tqdm(input_text)]\n",
    "input_text = [re.sub(\"\\d+\", \"\", i) for i in tqdm(input_text)]\n",
    "\n",
    "## remove more than one consecutive instance of x \n",
    "input_text=[re.sub(r'[x]{2,}',\"\",i) for i in tqdm(input_text)]\n",
    "\n",
    "## remove multiple spaces with a single space \n",
    "input_text=[re.sub(r' +',' ',i) for i in tqdm(input_text)]\n",
    "\n",
    "## remove '//\n",
    "input_text=[re.sub(r'[//]','',i) for i in tqdm(input_text)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Tokenize text \n",
    "tokenizer=BertTokenizer.from_pretrained('bert-base-cased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'i contacted ally on friday  after falling behind on payments due to being out of work for a short period of time due to an illness. i chated with a representative after logging into my account regarding my opitions to ensure i protect my credit and bring my account current. \\n\\nshe advised me that before an extenstion could be done, i had to make a payment in the amount of . i reviewed my finances, as i am playing catch up on all my bills and made this payment on monday . this rep advised me, once this payment posts to my account to contact ally back for an extention or to have a payment deffered to the end of my loan. \\n\\nwith this in mind, i contacted ally again today and chatted with . i explained all of the above and the information i was provided when i chatted with the rep last week. she asked several questions and advised me that a one or two month extensiondeffered payment could be done however partial payment is needed! what? she advised me or there abouts would be due within days from me accepting the agreement and then the remaining bal of or there abouts would be due in . in , my payments of per month would resume. \\n\\nif this was the case, i should have just been offered this when i just made my payment so that i could catch up on my bills. \\n\\nthis company was working with in new jersey which has since closed most likely due to illegal practices, they changed my loan company to this company after i had signed paperwork for another, kill you with interest rates and has never once considered refiancing my vechile for a lower interest rate ( due to the age of the vechile other companies will not take it ) and they do not work with you!'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_text[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "## a tokenization example\n",
    "sample_tokens = tokenizer(input_text[0], padding=True,\n",
    "                          max_length = seq_len, truncation = True,\n",
    "                          return_tensors='pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[  101,   178, 12017, 11989,  1113,   175, 22977,  1183,  1170,  4058,\n",
       "          1481,  1113, 10772,  1496,  1106,  1217,  1149,  1104,  1250,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[  101,   178, 12017, 11989,  1113,   175, 22977,  1183,  1170,  4058,\n",
       "          1481,  1113, 10772,  1496,  1106,  1217,  1149,  1104,  1250,   102]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_tokens[\"input_ids\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_tokens[\"attention_mask\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 241440/241440 [09:10<00:00, 438.43it/s]\n"
     ]
    }
   ],
   "source": [
    "## tokenization of all reviews in the data \n",
    "tokens = [tokenizer(i, padding=\"max_length\", max_length=seq_len, \n",
    "                    truncation=True, return_tensors=\"pt\") \n",
    "         for i in tqdm(input_text)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<div style=\"background-color:#F0E3D2; color:#19180F; font-size:15px; font-family:Verdana; padding:10px; border: 2px solid #19180F; border-radius:10px\"> \n",
    "ðŸ“Œ\n",
    "Save tokens\n",
    "    </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<div style=\"background-color:#D5D9F2; color:#19180F; font-size:20px; font-family:verdana; padding:10px; border: 5px solid #19180F; border-radius:10px \"> \n",
    "Now that we have our tokens prepared as input for our model, I choose to save them on disk. This will be useful if I need to use them for another task with the same model (BERT) in the future. Or if some one needs to reproduce this project, he can just use my tokens directly (if he is using the same model of course). \n",
    "</div>\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_file(tokens_path, tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color:#F1C40F; color:#C0392B; font-size:40px; font-family:Arial; padding:10px; border: 5px solid #19180F; border-radius:10px\"> II. Create BERT Model</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<div style=\"background-color:#F0E3D2; color:#19180F; font-size:15px; font-family:Verdana; padding:10px; border: 2px solid #19180F; border-radius:10px\"> \n",
    "ðŸ“Œ\n",
    "ClassifierBert class \n",
    "    </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BertClassifier(nn.Module):\n",
    "    \n",
    "    def __init__(self, dropout, num_classes):\n",
    "        super(BertClassifier, self).__init__()\n",
    "        self.bert = BertModel.from_pretrained('bert-base-cased')\n",
    "        for param in self.bert.parameters():\n",
    "            param.required_grad = False\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.linear = nn.Linear(768, num_classes)\n",
    "        self.activation = nn.ReLU()\n",
    "    \n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        _, bert_output = self.bert(input_ids=input_ids,\n",
    "                                  attention_mask=attention_mask,\n",
    "                                  return_dict=False)\n",
    "        dropout_output = self.activation(self.dropout(bert_output))\n",
    "        final_output = self.linear(dropout_output)\n",
    "        return final_output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<div style=\"background-color:#F0E3D2; color:#19180F; font-size:15px; font-family:Verdana; padding:10px; border: 2px solid #19180F; border-radius:10px\"> \n",
    "ðŸ“Œ\n",
    "Pytorch Dataset\n",
    "    </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextDataset(torch.utils.data.Dataset):\n",
    "    \n",
    "    def __init__(self, tokens, labels):\n",
    "        self.tokens = tokens\n",
    "        self.labels = labels\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.tokens)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.labels[idx], self.tokens[idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<div style=\"background-color:#F0E3D2; color:#19180F; font-size:15px; font-family:Verdana; padding:10px; border: 2px solid #19180F; border-radius:10px\"> \n",
    "ðŸ“Œ\n",
    "Function to train the model\n",
    "    </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "def train(train_loader, valid_loader, model, criterion, optimizer, device, num_epochs, model_path):\n",
    "    \"\"\"\n",
    "    Function to train the model\n",
    "    :param train_loader: Data loader for train dataset\n",
    "    :param valid_loader: Data loader for validation dataset\n",
    "    :param model: Model object\n",
    "    :param criterion: Loss function\n",
    "    :param optimizer: Optimizer\n",
    "    :param device: CUDA or CPU\n",
    "    :param num_epochs: Number of epochs\n",
    "    :param model_path: Path to save the model\n",
    "    \"\"\"\n",
    "    # We initialize the best loss with a large value\n",
    "    best_loss = 1e8\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print(f\"Epoch {epoch+1} of {num_epochs}\")\n",
    "        # For each epoch, create lists to store losses\n",
    "        train_loss = []\n",
    "        valid_loss = []\n",
    "        \n",
    "        model.train()\n",
    "        \n",
    "        # Train loop\n",
    "        for batch_labels, batch_data in tqdm(train_loader):\n",
    "            input_ids = batch_data[\"input_ids\"]\n",
    "            attention_mask = batch_data[\"attention_mask\"]\n",
    "            \n",
    "            # Move data to GPU if available\n",
    "            batch_labels = batch_labels.to(device)\n",
    "            input_ids = input_ids.to(device)\n",
    "            attention_mask = attention_mask.to(device)\n",
    "            input_ids = torch.squeeze(input_ids, 1)  # train_loader returns 3D tensors, we need 2D\n",
    "            \n",
    "            # Forward pass\n",
    "            batch_output = model(input_ids, attention_mask)\n",
    "            batch_output = torch.squeeze(batch_output)\n",
    "            \n",
    "            # Calculate loss\n",
    "            loss = criterion(batch_output, batch_labels)\n",
    "            \n",
    "            # Add batch_loss to train_loss list\n",
    "            train_loss.append(loss.item())\n",
    "            \n",
    "            # Prepare for backward pass\n",
    "            optimizer.zero_grad()  # Reset the gradients for each batch\n",
    "            \n",
    "            # Backward pass\n",
    "            loss.backward()\n",
    "            \n",
    "            # Gradient update step\n",
    "            optimizer.step()\n",
    "        \n",
    "        model.eval()\n",
    "        \n",
    "        # Validation loop\n",
    "        with torch.no_grad():\n",
    "            for batch_labels, batch_data in tqdm(valid_loader):\n",
    "                input_ids = batch_data[\"input_ids\"]\n",
    "                attention_mask = batch_data[\"attention_mask\"]\n",
    "                \n",
    "                # Move data to GPU if available\n",
    "                batch_labels = batch_labels.to(device)\n",
    "                input_ids = input_ids.to(device)\n",
    "                attention_mask = attention_mask.to(device)\n",
    "                input_ids = torch.squeeze(input_ids, 1)\n",
    "                \n",
    "                # Forward pass\n",
    "                batch_output = model(input_ids, attention_mask)\n",
    "                batch_output = torch.squeeze(batch_output)\n",
    "                \n",
    "                # Calculate loss\n",
    "                loss = criterion(batch_output, batch_labels)\n",
    "                \n",
    "                # Add batch_loss to valid_loss list\n",
    "                valid_loss.append(loss.item())\n",
    "        \n",
    "        # Compute the mean of train & valid loss for the epoch\n",
    "        t_loss = np.mean(train_loss)\n",
    "        v_loss = np.mean(valid_loss)\n",
    "        \n",
    "        print(f\"Train Loss: {t_loss}, Validation Loss: {v_loss}\")\n",
    "        \n",
    "        # Check if this is the best validation loss we've seen so far\n",
    "        if v_loss < best_loss:\n",
    "            best_loss = v_loss\n",
    "            # Save current model as the best model\n",
    "            torch.save(model.state_dict(), model_path)\n",
    "        \n",
    "        print(f\"Best Validation Loss: {best_loss}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<div style=\"background-color:#F0E3D2; color:#19180F; font-size:15px; font-family:Verdana; padding:10px; border: 2px solid #19180F; border-radius:10px\"> \n",
    "ðŸ“Œ\n",
    "Function to test the model\n",
    "    </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(test_loader, model, criterion, device):\n",
    "    \"\"\"\n",
    "    Function to test the model\n",
    "    :param test_loader: Data loader for test dataset\n",
    "    :param model: Model object\n",
    "    :param criterion: Loss function\n",
    "    :param device: CUDA or CPU\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    test_loss = []\n",
    "    test_accu = []\n",
    "    for batch_labels, batch_data in tqdm(test_loader):\n",
    "        input_ids = batch_data[\"input_ids\"]\n",
    "        attention_mask = batch_data[\"attention_mask\"]\n",
    "        # Move data to GPU if available\n",
    "        batch_labels = batch_labels.to(device)\n",
    "        input_ids = input_ids.to(device)\n",
    "        attention_mask = attention_mask.to(device)\n",
    "        input_ids = torch.squeeze(input_ids, 1)\n",
    "        # Forward pass\n",
    "        batch_output = model(input_ids, attention_mask)\n",
    "        batch_output = torch.squeeze(batch_output)\n",
    "        # Calculate loss\n",
    "        ###batch_labels = batch_labels.type(torch.LongTensor)\n",
    "        loss = criterion(batch_output, batch_labels)\n",
    "        test_loss.append(loss.item())\n",
    "        batch_preds = torch.argmax(batch_output, axis=1)\n",
    "        # Move predictions to CPU\n",
    "        if torch.cuda.is_available():\n",
    "            batch_labels = batch_labels.cpu()\n",
    "            batch_preds = batch_preds.cpu()\n",
    "        # Compute accuracy\n",
    "        test_accu.append(accuracy_score(batch_labels.detach().\n",
    "                                        numpy(),\n",
    "                                        batch_preds.detach().\n",
    "                                        numpy()))\n",
    "    test_loss = np.mean(test_loss)\n",
    "    test_accu = np.mean(test_accu)\n",
    "    print(f\"Test Loss: {test_loss}, Test Accuracy: {test_accu}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color:#F1C40F; color:#C0392B; font-size:40px; font-family:Arial; padding:10px; border: 5px solid #19180F; border-radius:10px\"> III. Train The  Model</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<div style=\"background-color:#F0E3D2; color:#19180F; font-size:15px; font-family:Verdana; padding:10px; border: 2px solid #19180F; border-radius:10px\"> \n",
    "ðŸ“Œ\n",
    "Load files    </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = load_file(tokens_path)\n",
    "labels = load_file(labels_path)\n",
    "label_encoder = load_file(label_encoder_path)\n",
    "num_classes = len(label_encoder.classes_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<div style=\"background-color:#F0E3D2; color:#19180F; font-size:15px; font-family:Verdana; padding:10px; border: 2px solid #19180F; border-radius:10px\"> \n",
    "ðŸ“Œ\n",
    "Split data into train, validatin and test     </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(tokens, labels,\n",
    "                                                   test_size=0.2)\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X_train, \n",
    "                                                      y_train,\n",
    "                                                     test_size=0.25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<div style=\"background-color:#F0E3D2; color:#19180F; font-size:15px; font-family:Verdana; padding:10px; border: 2px solid #19180F; border-radius:10px\"> \n",
    "ðŸ“Œ\n",
    "Create Pytorch datasets     </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = TextDataset(X_train, y_train)\n",
    "valid_dataset = TextDataset(X_valid, y_valid)\n",
    "test_dataset = TextDataset(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<div style=\"background-color:#F0E3D2; color:#19180F; font-size:15px; font-family:Verdana; padding:10px; border: 2px solid #19180F; border-radius:10px\"> \n",
    "ðŸ“Œ\n",
    "Create Data Loaders    </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(train_dataset,\n",
    "                                           batch_size=16,\n",
    "                                           shuffle=True,\n",
    "                                           drop_last=True)\n",
    "valid_loader = torch.utils.data.DataLoader(valid_dataset,\n",
    "                                           batch_size=16)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, \n",
    "                                         batch_size=16)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<div style=\"background-color:#F0E3D2; color:#19180F; font-size:15px; font-family:Verdana; padding:10px; border: 2px solid #19180F; border-radius:10px\"> \n",
    "ðŸ“Œ\n",
    "INstantiate model object    </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available()\n",
    "                     else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = BertClassifier(dropout, num_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<div style=\"background-color:#F0E3D2; color:#19180F; font-size:15px; font-family:Verdana; padding:10px; border: 2px solid #19180F; border-radius:10px\"> \n",
    "ðŸ“Œ\n",
    "Define loss function and optimizer    </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<div style=\"background-color:#F0E3D2; color:#19180F; font-size:15px; font-family:Verdana; padding:10px; border: 2px solid #19180F; border-radius:10px\"> \n",
    "ðŸ“Œ\n",
    "Move the model to GPU if available    </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    model = model.cuda()\n",
    "    criterion = criterion.cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<div style=\"background-color:#F0E3D2; color:#19180F; font-size:15px; font-family:Verdana; padding:10px; border: 2px solid #19180F; border-radius:10px\"> \n",
    "ðŸ“Œ\n",
    "Train loop   </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 of 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9054/9054 [05:02<00:00, 29.95it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3018/3018 [00:23<00:00, 131.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.5812722926164058, Validation Loss: 1.5352410966193464\n",
      "Best Validation Loss: 1.5352410966193464\n",
      "Epoch 2 of 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9054/9054 [05:10<00:00, 29.21it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3018/3018 [00:22<00:00, 131.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.5798125248464074, Validation Loss: 1.55237182652895\n",
      "Best Validation Loss: 1.5352410966193464\n",
      "Epoch 3 of 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9054/9054 [05:05<00:00, 29.68it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3018/3018 [00:23<00:00, 131.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.5830056611304517, Validation Loss: 1.5166558558337335\n",
      "Best Validation Loss: 1.5166558558337335\n",
      "Epoch 4 of 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9054/9054 [05:11<00:00, 29.03it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3018/3018 [00:23<00:00, 131.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.5806448261864747, Validation Loss: 1.5286006583647669\n",
      "Best Validation Loss: 1.5166558558337335\n",
      "Epoch 5 of 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9054/9054 [04:57<00:00, 30.44it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3018/3018 [00:23<00:00, 131.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.5803480836922217, Validation Loss: 1.5645999267766457\n",
      "Best Validation Loss: 1.5166558558337335\n",
      "Epoch 6 of 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9054/9054 [04:58<00:00, 30.32it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3018/3018 [00:22<00:00, 131.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.5809528193964661, Validation Loss: 1.5277305251719384\n",
      "Best Validation Loss: 1.5166558558337335\n",
      "Epoch 7 of 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9054/9054 [05:00<00:00, 30.10it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3018/3018 [00:23<00:00, 131.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.5815212822115814, Validation Loss: 1.5313032572438496\n",
      "Best Validation Loss: 1.5166558558337335\n",
      "Epoch 8 of 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9054/9054 [05:02<00:00, 29.95it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3018/3018 [00:22<00:00, 131.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.5795763257997095, Validation Loss: 1.5868910046465907\n",
      "Best Validation Loss: 1.5166558558337335\n",
      "Epoch 9 of 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9054/9054 [05:04<00:00, 29.71it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3018/3018 [00:22<00:00, 131.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.581666468895901, Validation Loss: 1.5503532421004307\n",
      "Best Validation Loss: 1.5166558558337335\n",
      "Epoch 10 of 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9054/9054 [05:09<00:00, 29.21it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3018/3018 [00:22<00:00, 131.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.5813977529150987, Validation Loss: 1.5894147534296164\n",
      "Best Validation Loss: 1.5166558558337335\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "train(train_loader, valid_loader, model, criterion, optimizer,\n",
    "     device, num_epochs, model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<div style=\"background-color:#F0E3D2; color:#19180F; font-size:15px; font-family:Verdana; padding:10px; border: 2px solid #19180F; border-radius:10px\"> \n",
    "ðŸ“Œ\n",
    "Test loop </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3018/3018 [00:27<00:00, 111.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 1.6000038638385106, Test Accuracy: 0.521392478462558\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "test(test_loader, model, criterion, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<div style=\"background-color:#F0E3D2; color:#19180F; font-size:15px; font-family:Verdana; padding:10px; border: 2px solid #19180F; border-radius:10px\"> \n",
    "ðŸ“Œ\n",
    "Predict on new text </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_text = '''I am a victim of Identity Theft & currently have an Experian account that \n",
    "I can view my Experian Credit Report and getting notified when there is activity on \n",
    "my Experian Credit Report. For the past 3 days I've spent a total of approximately 9 \n",
    "hours on the phone with Experian. Every time I call I get transferred repeatedly and \n",
    "then my last transfer and automated message states to press 1 and leave a message and \n",
    "someone would call me. Every time I press 1 I get an automatic message stating than you \n",
    "before I even leave a message and get disconnected. I call Experian again, explain what \n",
    "is happening and the process begins again with the same end result. I was trying to have \n",
    "this issue attended and resolved informally but I give up after 9 hours. There are hard \n",
    "hit inquiries on my Experian Credit Report that are fraud, I didn't authorize, or recall \n",
    "and I respectfully request that Experian remove the hard hit inquiries immediately just \n",
    "like they've done in the past when I was able to speak to a live Experian representative \n",
    "in the United States. The following are the hard hit inquiries : BK OF XXXX XX/XX/XXXX \n",
    "XXXX XXXX XXXX  XX/XX/XXXX XXXX  XXXX XXXX  XX/XX/XXXX XXXX  XX/XX/XXXX XXXX  XXXX \n",
    "XX/XX/XXXX'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_text = input_text.lower()\n",
    "input_text = re.sub(r\"[^\\w\\d'\\s]+\", \" \", input_text)\n",
    "input_text = re.sub(\"\\d+\", \"\", input_text)\n",
    "input_text = re.sub(r'[x]{2,}', \"\", input_text)\n",
    "input_text = re.sub(' +', ' ', input_text)\n",
    "\n",
    "# use the same tokenizer \n",
    "tokenizer = BertTokenizer.from_pretrained(\"bert-base-cased\")\n",
    "\n",
    "# encode text with the tokenizer \n",
    "tokens = tokenizer(input_text, padding=\"max_length\",\n",
    "                 max_length=seq_len, truncation=True,\n",
    "                 return_tensors=\"pt\")\n",
    "\n",
    "input_ids = tokens[\"input_ids\"]\n",
    "attention_mask = tokens[\"attention_mask\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available()\n",
    "                     else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ids = input_ids.to(device)\n",
    "attention_mask = attention_mask.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ids = torch.squeeze(input_ids, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_encoder = load_file(label_encoder_path)\n",
    "num_classes = len(label_encoder.classes_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Class: credit_report\n"
     ]
    }
   ],
   "source": [
    "# Create model object\n",
    "model = BertClassifier(dropout, num_classes)\n",
    "\n",
    "# Load trained weights\n",
    "model.load_state_dict(torch.load(model_path))\n",
    "\n",
    "# Move the model to GPU if available\n",
    "if torch.cuda.is_available():\n",
    "    model = model.cuda()\n",
    "    \n",
    "# Forward pass\n",
    "out = torch.squeeze(model(input_ids, attention_mask))\n",
    "\n",
    "# Find predicted class\n",
    "prediction = label_encoder.classes_[torch.argmax(out)]\n",
    "print(f\"Predicted Class: {prediction}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bert",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
